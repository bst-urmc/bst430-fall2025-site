<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>BST430 Lecture 16</title>
    <meta charset="utf-8" />
    <meta name="author" content="Tanzy Love, based on the course by Andrew McDavid" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/all.css" rel="stylesheet" />
    <link href="libs/font-awesome/css/v4-shims.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: ur-title, center, middle, title-slide

.title[
# BST430 Lecture 16
]
.subtitle[
## Multivariate linear models
]
.author[
### Tanzy Love, based on the course by Andrew McDavid
]
.institute[
### U of Rochester
]
.date[
### 2021-11-07 (updated: 2022-11-15 by TL)
]

---

  






  
# Agenda

0.  Multivariate plots
1.  More modeling syntax
3.  Diagnostics
4. Prediction

---

class: code70

### `mtcars`

- For this lesson, we will use the (infamous) `mtcars` dataset that comes
  with R by default.

```r
library(tidyverse)
library(broom)
data("mtcars")
glimpse(mtcars)
```

```
## Rows: 32
## Columns: 11
## $ mpg  &lt;dbl&gt; 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22~
## $ cyl  &lt;dbl&gt; 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8,~
## $ disp &lt;dbl&gt; 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 1~
## $ hp   &lt;dbl&gt; 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123~
## $ drat &lt;dbl&gt; 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.~
## $ wt   &lt;dbl&gt; 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3~
## $ qsec &lt;dbl&gt; 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 2~
## $ vs   &lt;dbl&gt; 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,~
## $ am   &lt;dbl&gt; 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,~
## $ gear &lt;dbl&gt; 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3,~
## $ carb &lt;dbl&gt; 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4,~
```

???

1974 Motor Trend US magazine, and comprises fuel consumption and 10 aspects of automobile design and performance for 32 automobiles.

[, 1]	mpg	Miles/(US) gallon
[, 2]	cyl	Number of cylinders
[, 3]	disp	Displacement (cu.in.)
[, 4]	hp	Gross horsepower
[, 5]	drat	Rear axle ratio
[, 6]	wt	Weight (1000 lbs)
[, 7]	qsec	1/4 mile time
[, 8]	vs	Engine (0 = V-shaped, 1 = straight)
[, 9]	am	Transmission (0 = automatic, 1 = manual)
[,10]	gear	Number of forward gears
[,11]	carb	Number of carburetors

---

class: middle

.hand[Visualizing multivariate relationships]

---

### Exploratory data analyses of multivariate data

-  Hard
-  Necessary
-  Often generates quite a few plots before you identify one that you can keep

---

### One simple trick

Pairs plots!

.panelset[
.panel[.panel-name[Code]

```r
library(GGally)
GGally::ggpairs(mtcars)
```

]
.panel[.panel-name[Plot]
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-4-1.png" width="70%" style="display: block; margin: auto;" /&gt;

]
]

---

* Evidently `vs`, `am`, `gear` and maybe `cyl` should be cast to factors

.panelset[
.panel[.panel-name[Code]

```r
mtcars = mtcars %&gt;% mutate(across(c(vs, am, gear, cyl), factor))
GGally::ggpairs(mtcars)
```

]
.panel[.panel-name[Plot]
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-5-1.png" width="70%" style="display: block; margin: auto;" /&gt;

]
]

---

- Let's suppose we wanted to determine which variables affect fuel 
  consumption (the `mpg` variable in the dataset).
- `cyl`, `disp`, `hp`, `drat`, `wt` all appear to be correlated with `mpg`
- `vs`, `am` and possibly `gear` could have distributional differences, as well

---
class: code70

- To begin, we'll look at the association between the variables log-weight 
  and mpg


```r
ggplot(mtcars, aes(x = wt, mpg)) +
  geom_point() +
  scale_x_log10() +
  xlab("Weight") +
  ylab("Miles Per Gallon")
```

&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-6-1.png" width="60%" style="display: block; margin: auto;" /&gt;
    
- It seems that log-weight is negatively associated with mpg.
- It seems that the data approximately fall on a line.

---

### OLS fits in R

1. Make sure you have the explanatory variables in the format you want:
   
   ```r
   submt = mtcars %&gt;% mutate(logwt = log(wt))
   ```
2. Use `lm()`
   
   ```r
   lmout = lm(mpg ~ logwt, data = submt)
   lmtide = tidy(lmout)
   select(lmtide, term, estimate)
   ```
   
   ```
   ## # A tibble: 2 x 2
   ##   term        estimate
   ##   &lt;chr&gt;          &lt;dbl&gt;
   ## 1 (Intercept)     39.3
   ## 2 logwt          -17.1
   ```

---

### `lm` syntax

```r
lm(response ~ pred1 + pred2*pred3, data = data) 
```
Finds the OLS estimates of the following model: 

&gt; response = `\(\beta_0+ \beta_1\text{pred1} + \beta_2\text{pred2} + \beta_{3}\text{pred3}+ \beta_{23}\text{pred2} * \text{pred3}\)` + error
  
The `data` argument tells `lm()` where to find the response and 
  explanatory variables.

---

###  Formula syntax

*  `x:z` form the interaction between `x` and `z` -- this is element-by-element times if at least `x` or `z` is continuous, otherwise it is an outer-product.
*  `x*z` form interactions and include main effects. Equivalent to `x + z + x:z`
*  `+ 0` or `- 1` exclude an intercept term, or `- x` exclude `x` if included otherwise.
*  `(x + z + u)^2` form all two-way interactions and main effects with `x`, `z`, `u`.
*  `I(x - 10)` or `I(x^2)` -- perform arithmetic operations that use `+`, `-`, `*`, `^`, etc, on a variable "on-the-fly" in the formula.   Can also just transform before you model.
*  `y ~ .` every variable in the data, except the response `y`.

---
class: code50

### Example

.alert[But don't do this without thinking!]


```r
tidy(lm(mpg ~ ., data = mtcars))
```

```
## # A tibble: 13 x 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)  15.1      17.1        0.881   0.389
## 2 cyl6         -1.20      2.39      -0.502   0.621
## 3 cyl8          3.05      4.83       0.633   0.535
## 4 disp          0.0126    0.0177     0.708   0.487
## # ... with 9 more rows
```


For a predictive goal, probably should use some method that does shrinkage and basis expansion.  For inference, need to consider putative casual models.

---


- Use `broom::glance()` function to get the estimated standard deviation, `\(R^2\)`, and information criteria. It's the value
  in the `sigma` column.
    
    ```r
    glance(lmout)
    ```
    
    ```
    ## # A tibble: 1 x 12
    ##   r.squ~1 adj.r~2 sigma stati~3  p.value    df logLik   AIC   BIC
    ##     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
    ## 1   0.810   0.804  2.67    128. 2.39e-12     1  -75.8  158.  162.
    ## # ... with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;,
    ## #   nobs &lt;int&gt;, and abbreviated variable names 1: r.squared,
    ## #   2: adj.r.squared, 3: statistic
    ```

---

# Prediction (Interpolation)

- **Interpolation**: Making estimates/predictions within the range of the data.
- **Extrapolation**: Making estimates/predictions outside the range of the data.
- Interpolation is fine. Extrapolation is dangerous.
.question[why?]

---

- Interpolation
    &lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-11-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

- Extrapolation
    &lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-12-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Why is extrapolation dangerous?

1. Not sure if the linear relationship is the same outside the range of
   the data (because we don't have data there to see the relationship).
2. Not sure if the variability is the same outside the range of the 
   data (because we don't have data there to see the variability).

---

### Make a prediction:

1. You need a data frame with the exact same
   variable name as the explanatory variable. 
   
   ```r
   newdf = tribble(~logwt,
                   1, 
                   1.5)
   ```
2. Then you use the `predict()` function to obtain predictions.
   
   ```r
   newdf = newdf %&gt;%
     mutate(predictions = predict(object = lmout, newdata = newdf))
   ```

---

## Assumptions and Violations

- In the linear model, you can trade assumptions for inference:

- Assumptions in *decreasing* order of importance
  1. **Independence** - The knowledge of the value of one observation does not 
     give you any information on the value of another.
  2. **Linearity** - The relationship looks like a straight line.
  3. **Equal Variance** - The spread is the same for every value of `\(x\)`
  4. **Normality** - The distribution of the errors isn't too skewed and there aren't 
     any *too* extreme points. (Only an issue if you have outliers and a 
     small number of observations because thanks be to the 
     [central limit theorem](https://en.wikipedia.org/wiki/Central_limit_theorem)).

---

### What do we lose when violated?

  1. **Linearity** violated - Linear regression line does not pick up actual 
     conditional expectation.  As a linear approximation, the results will be sensitive to the particular `\(x\)` sampled.
  2. **Independence** violated - Linear regression line is unbiased, but standard 
     errors can be badly off.
  3. **Equal Variance** violated - Linear regression line is unbiased, but standard 
     errors are off. Your `\(p\)`-values may be too small, or too large.
  4. **Normality** violated - Only an issue if your sample size is "small".  Unstable results if outliers are present.  Your `\(p\)`-values may be too small, or too large.
     
.question[What assumptions are made about the distribution of the 
  explanatory variable (the `\(x_i\)`'s)?]

---
  
## Evaluating Independence

- Think about the problem.
  - Were different responses measured on the same observational/experimental unit?
  - Were data collected in groups?

- Non-independence: The temperature today and the temperature 
  tomorrow. If it is warm today, it is probably warm tomorrow.

-  Non-independence: You are measuring properties of 500 single cells isolated from 3 mice.  Because the cells within a given mouse are probably similar, each cell is not independent.  

---

### xkcd 2533

&lt;img src="l16/img/slope_hypothesis_testing_2x.png" width="60%" style="display: block; margin: auto;" /&gt;

Via [xkcd](https://xkcd.com/2533/)



---
class: middle

# Interpreting coefficients when you log

---

### Log `x` 

Generally, when you use logs, you interpret associations on a 
  *multiplicative* scale instead of an *additive* scale.

No log:
- Model: `\(E[y_i] = \beta_0 + \beta_1 x_i\)`
- Observations that differ by 1 unit in `\(x\)` tend to differ by `\(\beta_1\)` units in `\(y\)`.

Log `\(x\)`:
- Model: `\(E[y_i] = \beta_0 + \beta_1 \log_2(x_i)\)`
- Observations that are twice as large in `\(x\)` tend to differ by `\(\beta_1\)` units in `\(y\)`.

---

### log `y` 

Log `\(y\)`:
- Model: `\(E[\log_2(y_i)] = \beta_0 + \beta_1 x_i\)`
- Observations that differ by 1 unit in `\(x\)` tend to be `\(2^{\beta_1}\)` times larger in `\(y\)`. 

Log both:
- Model: `\(E[\log_2(y_i)] = \beta_0 + \beta_1 \log_2(x_i)\)`
- Observations that are twice as large in `\(x\)` tend to be `\(2^{\beta_1}\)` times larger in `\(y\)`. 

.footnote[Note: we commit statistical abuse here, since `\(\exp \left[ \text{E}(\log(Y) | X) \right] \neq \text{E}(Y | X)\)`, ie, `exp` doesn't commute through the expectation. Though the delta method says this is the 1st order approximation.
]


---

# Summary of R commands

- `augment()`:
  - Residuals `\(r_i = y_i - \hat{y}_i\)`: `$.resid`
  - Fitted Values `\(\hat{y}_i\)`: `$.fitted`
- `tidy()`:
  - Name of variables: `$term`
  - Coefficient Estimates: `$estimate`
  - Standard Error (standard deviation of sampling distribution of coefficient estimates): `$std.error`
  - t-statistic: `$statistic`
  - p-value: `$p.value`
- `glance()`: 
  - R-squared value (proportion of variance explained by regression line, higher is better): `$r.squared`
  - AIC (lower is better): `$AIC`
  - BIC (lower is better): `$BIC`

---

# Prediction

---

## Goal: Building a spam filter

- Data: Set of emails and we know if each email is spam/not and other features 
- Use logistic regression to predict the probability that an incoming email is spam
- Optimize our model by picking the model with the best predictive performance

--
- Building a model to predict the probability that an email is spam is only half of the battle! We also need a decision rule about which emails get flagged as spam (e.g. what probability should we use as out cutoff?)

--
- A simple approach: choose a single threshold probability and any email that exceeds that probability is flagged as spam

---
class: middle

# Logistic regression

&lt;!-- --- --&gt;

&lt;!-- ## Generalized Linear Models (GLMs) --&gt;

&lt;!-- - Logistic regression is a *generalized linear model(GLM)* used to model a binary categorical outcome using numerical and categorical predictors --&gt;

&lt;!-- - A GLM is an extension of the least squares linear model `\(E(Y_i|\mathbf{x}_i) = \mathbf{x}_i \beta\)`, `\(\text{Var}(Y|\mathbf{x}_i) = \sigma^2\)` to --&gt;
&lt;!-- `$$g(E(Y_i|x_i)) = \eta_i = \mathbf{x}_i \beta$$` --&gt;
&lt;!-- , `\(Y|X \sim\)` Exponential-Family, and `\(g\)` is known as a **link** function. --&gt;

&lt;!-- - Whereby the glm allows non-linear effects in `\(\beta\)`, and since the conditional distribution of `\(Y|X\)` can include all sorts of interesting families, it also permits non-constant residual variance. --&gt;

&lt;!-- --- --&gt;

&lt;!-- ### The Bernoulli GLM with logit link --&gt;

&lt;!-- - To finish specifying the Logistic model we just need to define a reasonable link function that connects `\(\eta_i\)` to `\(p_i\)`: logit function --&gt;

&lt;!-- -- --&gt;
&lt;!-- - **Logit function:** For `\(0\le p \le 1\)` --&gt;

&lt;!-- `$$logit(p) = \log\left(\frac{p}{1-p}\right)$$` --&gt;


---

## Logit function, visualised

&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-16-1.png" width="60%" style="display: block; margin: auto;" /&gt;

---

## Properties of the logit

- The logit function takes a value between 0 and 1 and maps it to a value between `\(-\infty\)` and `\(\infty\)`

--
- Inverse logit (aka expit) function takes real values back to the probability space
&lt;!-- `$$g^{-1}(x) = \frac{\exp(x)}{1+\exp(x)} = \frac{1}{1+\exp(-x)}$$` --&gt;

--
- The expit function takes a value between `\(-\infty\)` and `\(\infty\)` and maps it to a value between 0 and 1

--
- This formulation is also useful for interpreting the model, since the logit can be interpreted as the log odds of a success -- more on this later

&lt;!-- --- --&gt;

&lt;!-- ## The logistic regression model --&gt;

&lt;!-- - Based on the three GLM criteria we have --&gt;
&lt;!--   - `\(y_i|x_i \sim \text{Bern}(p_i)\)` --&gt;
&lt;!--   - `\(\text{logit}(p_i) = \eta_i\)` --&gt;
&lt;!--   - `\(\eta_i = \beta_0+\beta_1 x_{1,i} + \cdots + \beta_n x_{n,i}\)` --&gt;

&lt;!-- -- --&gt;
&lt;!-- - From which we get --&gt;

&lt;!-- `$$p_i = \frac{\exp(\beta_0+\beta_1 x_{1,i} + \cdots + \beta_k x_{k,i})}{1+\exp(\beta_0+\beta_1 x_{1,i} + \cdots + \beta_k x_{k,i})}$$` --&gt;

---

## Modeling spam

In R we fit a GLM in the same way as a linear model except we

- use `"glm"` instead of `"lm"` as the engine 

- define `family = "binomial"` for the link function to be used in the model

--

- When using `tidymodels`, specify the model with `logistic_reg()`

---

## Prediction

- The mechanics of prediction is **easy**:
  - Plug in values of predictors to the model equation
  - Calculate the predicted value of the response variable, `\(\hat{y}\)`

--
- Getting it right is **hard**!
  - There is no guarantee the model estimates you have are correct
  - Or that your model will perform as well with new data as it did with your sample data

---

## Underfitting and overfitting

&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-17-1.png" width="70%" style="display: block; margin: auto;" /&gt;

---

## Spending our data

- Several steps to create a useful model: parameter estimation, model selection, performance assessment, etc.

- Doing all of this on the entire data we have available can lead to **overfitting**

- Allocate specific subsets of data for different tasks, as opposed to allocating the largest possible amount to the model parameter estimation only (which is what we've done so far)

---

class: middle

# Splitting data

---

## Splitting data

- **Training set:**
  - Sandbox for model building 
  - Spend most of your time using the training set to develop the model
  - Majority of the data (usually 80%)
  
- **Testing set:**
  - Held in reserve to determine efficacy of one or two chosen models
  - Critical to look at it once, otherwise it becomes part of the modeling process
  - Remainder of the data (usually 20%)
  
---

## Performing the split


```r
# Fix random numbers by setting the seed 
# Enables analysis to be reproducible when random numbers are used 
set.seed(20211115)

# Put 80% of the data into the training set 
email_split = initial_split(email, prop = 0.80)

# Create data frames for the two sets:
train_data = training(email_split)
test_data  = testing(email_split)
```

.font70[`training` / `testing` aren't doing anything very fancy -- just using `sample_n` and then taking its complement, but this approach generalizes to more complicated ways to split our data.]

---
class: code70

## Peek at the split

.small[
.pull-left[

```r
glimpse(train_data)
```

```
## Rows: 3,136
## Columns: 21
## $ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, ~
## $ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ cc           &lt;int&gt; 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 0, 0, 0, ~
## $ sent_email   &lt;fct&gt; 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, ~
## $ time         &lt;dttm&gt; 2012-01-23 19:23:58, 2012-03-28 09:13:47,~
## $ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ dollar       &lt;dbl&gt; 0, 0, 0, 0, 2, 0, 0, 0, 4, 0, 0, 0, 4, 0, ~
## $ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no~
## $ inherit      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, ~
## $ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ password     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ num_char     &lt;dbl&gt; 24.832, 4.998, 3.568, 26.110, 7.870, 5.127~
## $ line_breaks  &lt;int&gt; 624, 114, 81, 652, 253, 120, 74, 118, 190,~
## $ format       &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ~
## $ re_subj      &lt;fct&gt; 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, ~
## $ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ exclaim_mess &lt;dbl&gt; 2, 0, 1, 1, 8, 0, 0, 2, 5, 0, 8, 0, 8, 1, ~
## $ number       &lt;fct&gt; small, small, small, small, big, small, sm~
```
]
.pull-right[

```r
glimpse(test_data)
```

```
## Rows: 785
## Columns: 21
## $ spam         &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ to_multiple  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, ~
## $ from         &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ cc           &lt;int&gt; 1, 2, 1, 7, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, ~
## $ sent_email   &lt;fct&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, ~
## $ time         &lt;dttm&gt; 2012-01-01 14:38:32, 2012-01-01 18:32:53,~
## $ image        &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ~
## $ attach       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, ~
## $ dollar       &lt;dbl&gt; 0, 2, 0, 0, 0, 2, 0, 9, 0, 0, 0, 0, 0, 0, ~
## $ winner       &lt;fct&gt; no, no, no, no, no, no, no, no, no, no, no~
## $ inherit      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ viagra       &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ password     &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ num_char     &lt;dbl&gt; 15.075, 19.693, 3.959, 0.334, 1.482, 4.103~
## $ line_breaks  &lt;int&gt; 354, 330, 81, 9, 24, 173, 107, 151, 76, 41~
## $ format       &lt;fct&gt; 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ~
## $ re_subj      &lt;fct&gt; 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, ~
## $ exclaim_subj &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ~
## $ urgent_subj  &lt;fct&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ~
## $ exclaim_mess &lt;dbl&gt; 10, 4, 1, 0, 0, 0, 0, 1, 4, 0, 8, 2, 1, 3,~
## $ number       &lt;fct&gt; small, big, small, small, none, small, sma~
```
]
]

---

class: middle

# Modeling workflow

---

## Fit a model to the training dataset


```r
email_fit = logistic_reg() %&gt;%
  set_engine("glm") %&gt;%
  fit(spam ~ ., data = train_data, family = "binomial")
```

```
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
```

---

## Categorical predictors

&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-22-1.png" width="75%" style="display: block; margin: auto;" /&gt;

---

## Fit a model to the training dataset


```r
email_fit = logistic_reg() %&gt;%
  set_engine("glm") %&gt;%
* fit(spam ~ . - from - sent_email - viagra, data = train_data, family = "binomial")
```

```
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
```

.code50[

```r
email_fit
```

```
## parsnip model object
## 
## 
## Call:  stats::glm(formula = spam ~ . - from - sent_email - viagra, family = stats::binomial, 
##     data = data)
## 
## Coefficients:
##  (Intercept)  to_multiple1            cc          time         image        attach        dollar  
##   -1.043e+02    -2.802e+00     2.799e-02     7.810e-08    -3.578e+00     6.103e-01    -7.948e-02  
##    winneryes       inherit      password      num_char   line_breaks       format1      re_subj1  
##    2.111e+00     4.099e-01    -7.562e-01     6.814e-02    -5.259e-03    -9.421e-01    -3.474e+00  
## exclaim_subj  urgent_subj1  exclaim_mess   numbersmall     numberbig  
##    2.886e-01     2.734e+00     7.918e-03    -7.879e-01     2.957e-02  
## 
## Degrees of Freedom: 3135 Total (i.e. Null);  3117 Residual
## Null Deviance:	    1933 
## Residual Deviance: 1413 	AIC: 1451
```
]

???

Dropping `from`, `sent_email` quells the warnings about predicted probabilities being 0/1. Actually some of these variables might have predictive power, but we would need a more sophisticated approach than logistic regression to use them

---

## Predict outcome on the testing dataset


```r
predict(email_fit, test_data)
```

```
## # A tibble: 785 x 1
##   .pred_class
##   &lt;fct&gt;      
## 1 0          
## 2 0          
## 3 0          
## 4 0          
## # ... with 781 more rows
```


---

## Predict probabilities on the testing dataset


```r
email_pred = predict(email_fit, test_data, type = "prob") %&gt;%
  bind_cols(test_data %&gt;% select(spam, time))

email_pred
```

```
## # A tibble: 785 x 4
##   .pred_0 .pred_1 spam  time               
##     &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;dttm&gt;             
## 1   0.999 0.00127 0     2012-01-01 14:38:32
## 2   0.996 0.00373 0     2012-01-01 18:32:53
## 3   0.994 0.00596 0     2012-01-01 22:16:39
## 4   0.992 0.00801 0     2012-01-02 19:07:51
## # ... with 781 more rows
```

---

## A closer look at predictions



```r
email_pred %&gt;%
  arrange(desc(.pred_1)) %&gt;%
  print(n = 10)
```

```
## # A tibble: 785 x 4
##    .pred_0 .pred_1 spam  time               
##      &lt;dbl&gt;   &lt;dbl&gt; &lt;fct&gt; &lt;dttm&gt;             
##  1  0.0970   0.903 1     2012-03-27 01:17:01
##  2  0.165    0.835 1     2012-03-01 00:40:27
*##  3  0.191    0.809 1     2012-01-21 16:55:55
##  4  0.206    0.794 0     2012-01-02 22:30:31
##  5  0.243    0.757 1     2012-03-31 05:20:24
##  6  0.258    0.742 1     2012-03-17 12:20:57
*##  7  0.288    0.712 0     2012-02-03 08:25:39
##  8  0.293    0.707 1     2012-02-24 19:43:44
##  9  0.308    0.692 0     2012-01-31 10:07:48
## 10  0.346    0.654 0     2012-02-04 05:39:37
## # ... with 775 more rows
```

---

## Evaluate the performance

**Receiver operating characteristic (ROC) curve**&lt;sup&gt;+&lt;/sup&gt; which plot true positive rate vs. false positive rate (1 - specificity)

.pull-left[

```r
email_pred %&gt;%
  roc_curve(
    truth = spam,
    .pred_1,
    event_level = "second"
  ) %&gt;%
  autoplot()
```
]
.pull-right[
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-28-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

.footnote[
.small[
&lt;sup&gt;+&lt;/sup&gt;Originally developed for operators of military radar receivers, hence the name.
]
]

---

## Evaluate the performance

Find the area under the curve:

.pull-left[

```r
email_pred %&gt;%
  roc_auc(
    truth = spam,
    .pred_1,
    event_level = "second"
  )
```

```
## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.840
```
]
.pull-right[
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-30-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]


---

class: middle

# Feature engineering

---

## Feature engineering

- There are all sorts of ways to build predictive models of binary variables: random forests, support vector machines, neural networks, `\(k\)` nearest neighbors, gradient boosting, ...

- In their own way, each learns the mapping `\(\hat f: \mathbf{x} \mapsto Y\)`

--
- But the variables `\(\mathbf{x}\)` that go into the model and how they are represented are just as critical to success of the model

--
- **Feature engineering** allows us to get creative with our predictors in an effort to make them more useful for our model (to increase its predictive performance) 

-  How this engineering is done is part of the learned function `\(\hat f\)`, and needs to be accounted for when we evaluate our models.

---

## A simple approach: `mutate()`


```r
library(lubridate)
train_data %&gt;%
  mutate(
    date = date(time),
    dow  = wday(time),
    month = month(time)
    ) %&gt;%
  select(time, date, dow, month) %&gt;%
  sample_n(size = 5) # shuffle to show a variety
```

```
## # A tibble: 5 x 4
##   time                date         dow month
##   &lt;dttm&gt;              &lt;date&gt;     &lt;dbl&gt; &lt;dbl&gt;
## 1 2012-01-31 17:06:58 2012-01-31     3     1
## 2 2012-02-02 14:38:31 2012-02-02     5     2
## 3 2012-02-14 06:17:18 2012-02-14     3     2
## 4 2012-03-05 12:55:12 2012-03-05     2     3
## 5 2012-02-23 13:12:30 2012-02-23     5     2
```

???

time would be used a "seconds" since the epoch as a continuous variable, however this would not allow any flexibility about weekdays vs weekends, time of year, etc.

however, we would need to repeat this mutate on train / test independently, at a minimum this would not keep things D.R.Y.

It's actually even worse than that, in that some mutates (collapsing factors, scaling variables) have implicitly learned parameters -- if we don't account for this we can end up with data leaking between training and test or with garbage predictions in test


---

## Modeling workflow, revisited

- Create a **recipe** for feature engineering steps to be applied to the training data

--
- Fit the model to the training data after these steps have been applied

--
- Using the model estimates from the training data, predict outcomes for the test data

--
- Evaluate the performance of the model on the test data

---

class: middle

# Building recipes


???

Fancy mutate statements that can be applied easily to both training / test
Actually, is building up and saving a set of functions (without evaluating them)

---

## Initiate a recipe


```r
email_rec = recipe(
  spam ~ .,          # formula
  data = train_data  # data to use for cataloguing names and types of variables
  )

summary(email_rec)
```

.code50[

```
## # A tibble: 21 x 4
##    variable     type    role      source  
##    &lt;chr&gt;        &lt;chr&gt;   &lt;chr&gt;     &lt;chr&gt;   
##  1 to_multiple  nominal predictor original
##  2 from         nominal predictor original
##  3 cc           numeric predictor original
##  4 sent_email   nominal predictor original
##  5 time         date    predictor original
##  6 image        numeric predictor original
##  7 attach       numeric predictor original
##  8 dollar       numeric predictor original
##  9 winner       nominal predictor original
## 10 inherit      numeric predictor original
## 11 viagra       numeric predictor original
## 12 password     numeric predictor original
## 13 num_char     numeric predictor original
## 14 line_breaks  numeric predictor original
## 15 format       nominal predictor original
## 16 re_subj      nominal predictor original
## 17 exclaim_subj numeric predictor original
## 18 urgent_subj  nominal predictor original
## 19 exclaim_mess numeric predictor original
## 20 number       nominal predictor original
## 21 spam         nominal outcome   original
```
]

---

## Remove certain variables


```r
email_rec = email_rec %&gt;%
  step_rm(from, sent_email)
```

.code70[

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         20
## 
## Operations:
## 
## Variables removed from, sent_email
```
]

---

## Feature engineer date


```r
email_rec = email_rec %&gt;%
  step_date(time, features = c("dow", "month")) %&gt;%
  step_rm(time)
```

.code70[

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         20
## 
## Operations:
## 
## Variables removed from, sent_email
## Date features from time
## Variables removed time
```
]

---

## Discretize numeric variables


```r
email_rec = email_rec %&gt;%
  step_cut(cc, attach, dollar, breaks = c(0, 1)) %&gt;%
  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20))
```

.code70[

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         20
## 
## Operations:
## 
## Variables removed from, sent_email
## Date features from time
## Variables removed time
## Cut numeric for cc, attach, dollar
## Cut numeric for inherit, password
```
]

---

## Create dummy variables


```r
email_rec = email_rec %&gt;%
  step_dummy(all_nominal(), -all_outcomes())
```

.code70[

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         20
## 
## Operations:
## 
## Variables removed from, sent_email
## Date features from time
## Variables removed time
## Cut numeric for cc, attach, dollar
## Cut numeric for inherit, password
## Dummy variables from all_nominal(), -all_outcomes()
```
]

---

## Remove zero variance variables

Variables that contain only a single value


```r
email_rec = email_rec %&gt;%
  step_zv(all_predictors())
```

.code70[

```
## Recipe
## 
## Inputs:
## 
##       role #variables
##    outcome          1
##  predictor         20
## 
## Operations:
## 
## Variables removed from, sent_email
## Date features from time
## Variables removed time
## Cut numeric for cc, attach, dollar
## Cut numeric for inherit, password
## Dummy variables from all_nominal(), -all_outcomes()
## Zero variance filter on all_predictors()
```
]

---

## All in one place


```r
email_rec = recipe(spam ~ ., data = email) %&gt;%
  step_rm(from, sent_email) %&gt;%
  step_date(time, features = c("dow", "month")) %&gt;%               
  step_rm(time) %&gt;%
  step_cut(cc, attach, dollar, breaks = c(0, 1)) %&gt;%
  step_cut(inherit, password, breaks = c(0, 1, 5, 10, 20)) %&gt;%
  step_dummy(all_nominal(), -all_outcomes()) %&gt;%
  step_zv(all_predictors())
```

---

class: middle

# Building workflows

---

## Define model


```r
email_mod = logistic_reg() %&gt;% 
  set_engine("glm")

email_mod
```

```
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm
```

---

## Define workflow

**Workflows** bring together models and recipes so that they can be easily applied to both the training and test data.


```r
email_wflow = workflow() %&gt;% 
  add_model(email_mod) %&gt;% 
  add_recipe(email_rec)
```

.code60[

```
## == Workflow ========================================================================================
## Preprocessor: Recipe
## Model: logistic_reg()
## 
## -- Preprocessor ------------------------------------------------------------------------------------
## 7 Recipe Steps
## 
## * step_rm()
## * step_date()
## * step_rm()
## * step_cut()
## * step_cut()
## * step_dummy()
## * step_zv()
## 
## -- Model -------------------------------------------------------------------------------------------
## Logistic Regression Model Specification (classification)
## 
## Computational engine: glm
```
]

---

## Fit model to training data


```r
email_fit = email_wflow %&gt;% 
  fit(data = train_data)
```

```
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
```

---

.code50[

```r
tidy(email_fit)
```

```
## # A tibble: 30 x 5
##   term        estimate std.error statistic   p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
## 1 (Intercept) -1.18      0.273       -4.31 0.0000164
## 2 image       -2.00      0.976       -2.05 0.0408   
## 3 num_char     0.0611    0.0240       2.54 0.0111   
## 4 line_breaks -0.00517   0.00135     -3.82 0.000135 
## # ... with 26 more rows
```
]

---

## Make predictions for test data


```r
email_pred = predict(email_fit, test_data, type = "prob") %&gt;% 
  bind_cols(test_data) 

email_pred
```

```
## # A tibble: 785 x 23
##   .pred_0  .pred_1 spam  to_multiple from     cc sent_email
##     &lt;dbl&gt;    &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;       &lt;fct&gt; &lt;int&gt; &lt;fct&gt;     
## 1   0.999 0.000809 0     0           1         1 1         
## 2   0.998 0.00177  0     0           1         2 0         
## 3   0.996 0.00409  0     0           1         1 0         
## 4   0.996 0.00429  0     0           1         7 0         
##   time                image attach dollar winner inherit
##   &lt;dttm&gt;              &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;fct&gt;    &lt;dbl&gt;
## 1 2012-01-01 14:38:32     0      0      0 no           0
...
```

---

## Evaluate the performance

.pull-left[

```r
email_pred %&gt;%
  roc_curve(
    truth = spam,
    .pred_1,
    event_level = "second"
  ) %&gt;%
  autoplot()
```
]
.pull-right[
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-50-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

## Evaluate the performance

.pull-left[

```r
email_pred %&gt;%
  roc_auc(
    truth = spam,
    .pred_1,
    event_level = "second"
  )
```

```
## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.847
```
]
.pull-right[
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-52-1.png" width="100%" style="display: block; margin: auto;" /&gt;
]

---

class: middle

# Making decisions

---

## Cutoff probability: 0.5

.panelset[
.panel[.panel-name[Output]

Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.5**.


|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               700|            66|
|Email labelled spam     |                 8|            11|
]
.panel[.panel-name[Code]

```r
cutoff_prob = 0.5
email_pred %&gt;%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 &gt; cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %&gt;%
  count(spam_pred, spam) %&gt;%
  pivot_wider(names_from = spam, values_from = n) %&gt;%
  knitr::kable(col.names = c("", "Email is not spam", "Email is spam"))
```
]
]

---

## Cutoff probability: 0.25

.panelset[
.panel[.panel-name[Output]

Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.25**.


|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               644|            38|
|Email labelled spam     |                64|            39|
]
.panel[.panel-name[Code]

```r
cutoff_prob = 0.25
email_pred %&gt;%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 &gt; cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %&gt;%
  count(spam_pred, spam) %&gt;%
  pivot_wider(names_from = spam, values_from = n) %&gt;%
  knitr::kable(col.names = c("", "Email is not spam", "Email is spam"))
```
]
]

---

## Cutoff probability: 0.75

.panelset[
.panel[.panel-name[Output]

Suppose we decide to label an email as spam if the model predicts the probability of spam to be **more than 0.75**.


|                        | Email is not spam| Email is spam|
|:-----------------------|-----------------:|-------------:|
|Email labelled not spam |               705|            70|
|Email labelled spam     |                 3|             7|
]
.panel[.panel-name[Code]

```r
cutoff_prob = 0.75
email_pred %&gt;%
  mutate(
    spam      = if_else(spam == 1, "Email is spam", "Email is not spam"),
    spam_pred = if_else(.pred_1 &gt; cutoff_prob, "Email labelled spam", "Email labelled not spam")
    ) %&gt;%
  count(spam_pred, spam) %&gt;%
  pivot_wider(names_from = spam, values_from = n) %&gt;%
  knitr::kable(col.names = c("", "Email is not spam", "Email is spam"))
```
]
]

---

## Evaluating performance on training data

-  The training set does not have the capacity to be a good arbiter of performance.

--
- It is not an independent piece of information; predicting the training set can only reflect what the model already knows.

--
- Suppose you give a class a test, then give them the answers, then provide the same test. The student scores on the second test do not accurately reflect what they know about the subject; these scores would probably be higher than their results on the first test.

.footnote[
.small[
Source: [tidymodels.org](https://www.tidymodels.org/start/resampling/)
]
]

---

class: middle

# Cross validation

---

## Cross validation

More specifically, **v-fold cross validation**:

- Shuffle your data v partitions
- Use 1 partition for validation, and the remaining v-1 partitions for training
- Repeat v times

.footnote[
.small[
You might also heard of this referred to as k-fold cross validation.
]
]

---

## Cross validation

&lt;img src="l17/img/cross-validation.png" width="100%" style="display: block; margin: auto;" /&gt;

---

## Split data into folds

.pull-left[

```r
set.seed(345)

folds = vfold_cv(train_data, v = 5)
folds
```

```
## #  5-fold cross-validation 
## # A tibble: 5 x 2
##   splits             id   
##   &lt;list&gt;             &lt;chr&gt;
## 1 &lt;split [2508/628]&gt; Fold1
## 2 &lt;split [2509/627]&gt; Fold2
## 3 &lt;split [2509/627]&gt; Fold3
## 4 &lt;split [2509/627]&gt; Fold4
## 5 &lt;split [2509/627]&gt; Fold5
```
]
.pull-right[
&lt;img src="l17/img/cross-validation.png" width="100%" style="display: block; margin: auto 0 auto auto;" /&gt;
]

---
class: code60

## Fit resamples

.pull-left[

```r
set.seed(456)

email_fit_rs = email_wflow %&gt;%
  fit_resamples(folds)

email_fit_rs
```

```
## # Resampling results
## # 5-fold cross-validation 
## # A tibble: 5 x 4
##   splits             id    .metrics         .notes          
##   &lt;list&gt;             &lt;chr&gt; &lt;list&gt;           &lt;list&gt;          
## 1 &lt;split [2508/628]&gt; Fold1 &lt;tibble [2 x 4]&gt; &lt;tibble [2 x 3]&gt;
## 2 &lt;split [2509/627]&gt; Fold2 &lt;tibble [2 x 4]&gt; &lt;tibble [1 x 3]&gt;
## 3 &lt;split [2509/627]&gt; Fold3 &lt;tibble [2 x 4]&gt; &lt;tibble [1 x 3]&gt;
## 4 &lt;split [2509/627]&gt; Fold4 &lt;tibble [2 x 4]&gt; &lt;tibble [2 x 3]&gt;
## 5 &lt;split [2509/627]&gt; Fold5 &lt;tibble [2 x 4]&gt; &lt;tibble [1 x 3]&gt;
## 
## There were issues with some computations:
## 
##   - Warning(s) x4: glm.fit: fitted probabilities numerically 0 or 1 occurredThere are new levels in a...   - Warning(s) x3: glm.fit: fitted probabilities numerically 0 or 1 occurredThere are new levels in a...
## 
## Run `show_notes(.Last.tune.result)` for more information.
```
]
.pull-right[
&lt;img src="l17/img/cross-validation-animated.gif" width="100%" style="display: block; margin: auto 0 auto auto;" /&gt;
]

---

## Collect CV metrics


```r
collect_metrics(email_fit_rs)
```

```
## # A tibble: 2 x 6
##   .metric  .estimator  mean     n std_err .config             
##   &lt;chr&gt;    &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               
## 1 accuracy binary     0.908     5 0.00395 Preprocessor1_Model1
## 2 roc_auc  binary     0.837     5 0.00384 Preprocessor1_Model1
```

---

## Deeper look into CV metrics

.panelset[
.panel[.panel-name[Raw]

```r
collect_metrics(email_fit_rs, summarize = FALSE) %&gt;%
  print(n = 10)
```

```
## # A tibble: 10 x 5
##    id    .metric  .estimator .estimate .config             
##    &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               
##  1 Fold1 accuracy binary         0.915 Preprocessor1_Model1
##  2 Fold1 roc_auc  binary         0.834 Preprocessor1_Model1
##  3 Fold2 accuracy binary         0.904 Preprocessor1_Model1
##  4 Fold2 roc_auc  binary         0.847 Preprocessor1_Model1
##  5 Fold3 accuracy binary         0.915 Preprocessor1_Model1
##  6 Fold3 roc_auc  binary         0.844 Preprocessor1_Model1
##  7 Fold4 accuracy binary         0.895 Preprocessor1_Model1
##  8 Fold4 roc_auc  binary         0.828 Preprocessor1_Model1
##  9 Fold5 accuracy binary         0.910 Preprocessor1_Model1
## 10 Fold5 roc_auc  binary         0.831 Preprocessor1_Model1
```
]
.panel[.panel-name[Pretty]

|Fold  | accuracy| roc_auc|
|:-----|--------:|-------:|
|Fold1 |    0.915|   0.834|
|Fold2 |    0.904|   0.847|
|Fold3 |    0.915|   0.844|
|Fold4 |    0.895|   0.828|
|Fold5 |    0.910|   0.831|
]
]


---

### Training data optimism

In the typical case, we use cross-validation to tune and select between models, then use the train/test split to evaluate the final chosen model

-  In this case, the training data does not severely overestimate the performance in testing or cross-validation.
-  In general, the gap between training and test is a function of the training *optimism*.
-  `\(\nearrow\)` model flexibility, `\(\nearrow\)` optimism
-  `\(\searrow\)` training set size, `\(\nearrow\)` optimism.

---

### Example of training optimism

.pull-left[

```r
set.seed(123)
train_data_small = train_data %&gt;% sample_n(size = 100)
overfit = fit(email_wflow, data = train_data_small)
overpredict = predict(overfit, train_data_small, type = "prob") %&gt;% 
  bind_cols(train_data_small)
```
]

.pull-right[
&lt;img src="l16-crossv-lm_files/figure-html/unnamed-chunk-65-1.png" width="90%" style="display: block; margin: auto;" /&gt;

```
## # A tibble: 1 x 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary             1
```
]

---

# Final announcements

*  You will have access to the lectures as long as github exists and provides hosting for websites.  
*  You will have access to your completed homework assignments on github as long as you have access to your github account.
*  I would rather that you not electronically redistribute the entirety of a graded assignment with another student&lt;sup&gt;1&lt;/sup&gt; 

.footnote[[1] Reminder: sharing graded assignments within a class year isn't technically prohibited, but sharing across class years is prohibited and is a violation of the academic honesty policy per department policy.]






---

# Acknowledgments

Adapted from David Gerard's [Stat 512](https://data-science-master.github.io/lectures/05_linear_regression/05_simple_linear_regression.html)

Data science in a box [U4D7](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d07-prediction-overfitting/u4-d07-prediction-overfitting.html#1) [U4D8](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d08-feature-engineering/u4-d08-feature-engineering.html#1) [U4D9](https://rstudio-education.github.io/datascience-box/course-materials/slides/u4-d09-cross-validation/u4-d09-cross-validation.html#1)

## Resources

- Chapter 25 from [RDS](https://r4ds.had.co.nz/).

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "3:2"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
